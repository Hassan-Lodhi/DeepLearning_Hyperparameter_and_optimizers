{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dda4f81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6565c059",
   "metadata": {},
   "source": [
    "Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e43071a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24260d60",
   "metadata": {},
   "source": [
    "Training the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "067ed7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train= x_train.reshape(x_train.shape[0],28,28,1)\n",
    "x_test=  x_test.reshape(x_test.shape[0],28,28,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41530f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(28,28,1)\n",
    "y_train=keras.utils.to_categorical(y_train)#,num_classes=)\n",
    "y_test=keras.utils.to_categorical(y_test)#, num_classes)\n",
    "x_train= x_train.astype('float32')\n",
    "x_test= x_test.astype('float32')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd45b87",
   "metadata": {},
   "source": [
    "Normalizing the traing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "183b6b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train /= 255\n",
    "x_test /=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ebe5cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "\n",
    "num_classes=10\n",
    "\n",
    "epochs=10\n",
    "\n",
    "def build_model(optimizer):\n",
    "    model=Sequential()\n",
    "    model.add(Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer= optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7e88c7",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fffed16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 47s 50ms/step - loss: 2.2490 - accuracy: 0.1645 - val_loss: 2.1475 - val_accuracy: 0.4352\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 43s 46ms/step - loss: 2.1014 - accuracy: 0.3468 - val_loss: 1.9833 - val_accuracy: 0.6565\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 43s 46ms/step - loss: 1.9468 - accuracy: 0.4914 - val_loss: 1.8062 - val_accuracy: 0.7192\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 44s 47ms/step - loss: 1.7815 - accuracy: 0.5786 - val_loss: 1.6221 - val_accuracy: 0.7634\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 44s 47ms/step - loss: 1.6142 - accuracy: 0.6345 - val_loss: 1.4436 - val_accuracy: 0.7888\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 44s 47ms/step - loss: 1.4575 - accuracy: 0.6711 - val_loss: 1.2804 - val_accuracy: 0.8041\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 44s 47ms/step - loss: 1.3213 - accuracy: 0.6963 - val_loss: 1.1382 - val_accuracy: 0.8156\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 44s 47ms/step - loss: 1.2007 - accuracy: 0.7142 - val_loss: 1.0175 - val_accuracy: 0.8239\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 44s 47ms/step - loss: 1.0954 - accuracy: 0.7300 - val_loss: 0.9172 - val_accuracy: 0.8337\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 50s 53ms/step - loss: 1.0147 - accuracy: 0.7431 - val_loss: 0.8351 - val_accuracy: 0.8402\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 35s 37ms/step - loss: 1.5070 - accuracy: 0.5827 - val_loss: 0.7123 - val_accuracy: 0.8462\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 34s 36ms/step - loss: 0.7112 - accuracy: 0.7954 - val_loss: 0.4534 - val_accuracy: 0.8860\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.5546 - accuracy: 0.8352 - val_loss: 0.3786 - val_accuracy: 0.9004\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 30s 32ms/step - loss: 0.4873 - accuracy: 0.8559 - val_loss: 0.3404 - val_accuracy: 0.9076\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 33s 35ms/step - loss: 0.4501 - accuracy: 0.8659 - val_loss: 0.3149 - val_accuracy: 0.9151\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 34s 36ms/step - loss: 0.4195 - accuracy: 0.8754 - val_loss: 0.2964 - val_accuracy: 0.9187\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 36s 38ms/step - loss: 0.3975 - accuracy: 0.8809 - val_loss: 0.2807 - val_accuracy: 0.9216\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 33s 35ms/step - loss: 0.3800 - accuracy: 0.8868 - val_loss: 0.2682 - val_accuracy: 0.9248\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 33s 35ms/step - loss: 0.3663 - accuracy: 0.8908 - val_loss: 0.2568 - val_accuracy: 0.9266\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 34s 36ms/step - loss: 0.3533 - accuracy: 0.8947 - val_loss: 0.2475 - val_accuracy: 0.9288\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 43s 45ms/step - loss: 0.2320 - accuracy: 0.9312 - val_loss: 0.0687 - val_accuracy: 0.9781\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 46s 49ms/step - loss: 0.0902 - accuracy: 0.9727 - val_loss: 0.0497 - val_accuracy: 0.9830\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 49s 52ms/step - loss: 0.0666 - accuracy: 0.9790 - val_loss: 0.0404 - val_accuracy: 0.9851\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 44s 47ms/step - loss: 0.0556 - accuracy: 0.9826 - val_loss: 0.0372 - val_accuracy: 0.9873\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 42s 45ms/step - loss: 0.0449 - accuracy: 0.9852 - val_loss: 0.0347 - val_accuracy: 0.9874\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 39s 42ms/step - loss: 0.0401 - accuracy: 0.9877 - val_loss: 0.0362 - val_accuracy: 0.9878\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 38s 41ms/step - loss: 0.0360 - accuracy: 0.9886 - val_loss: 0.0339 - val_accuracy: 0.9897\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 40s 43ms/step - loss: 0.0307 - accuracy: 0.9898 - val_loss: 0.0323 - val_accuracy: 0.9895\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 44s 47ms/step - loss: 0.0289 - accuracy: 0.9904 - val_loss: 0.0322 - val_accuracy: 0.9901\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 48s 51ms/step - loss: 0.0251 - accuracy: 0.9915 - val_loss: 0.0320 - val_accuracy: 0.9903\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 54s 56ms/step - loss: 0.2436 - accuracy: 0.9267 - val_loss: 0.0688 - val_accuracy: 0.9775\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 50s 54ms/step - loss: 0.0936 - accuracy: 0.9721 - val_loss: 0.0515 - val_accuracy: 0.9832\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 38s 41ms/step - loss: 0.0712 - accuracy: 0.9783 - val_loss: 0.0496 - val_accuracy: 0.9841\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 33s 35ms/step - loss: 0.0589 - accuracy: 0.9820 - val_loss: 0.0398 - val_accuracy: 0.9863\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 33s 36ms/step - loss: 0.0522 - accuracy: 0.9845 - val_loss: 0.0354 - val_accuracy: 0.9878\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 50s 54ms/step - loss: 0.0487 - accuracy: 0.9852 - val_loss: 0.0352 - val_accuracy: 0.9875\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 51s 54ms/step - loss: 0.0428 - accuracy: 0.9869 - val_loss: 0.0387 - val_accuracy: 0.9881\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 51s 54ms/step - loss: 0.0420 - accuracy: 0.9872 - val_loss: 0.0356 - val_accuracy: 0.9890\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 49s 53ms/step - loss: 0.0370 - accuracy: 0.9884 - val_loss: 0.0377 - val_accuracy: 0.9887\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 36s 38ms/step - loss: 0.0384 - accuracy: 0.9883 - val_loss: 0.0317 - val_accuracy: 0.9892\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 28s 29ms/step - loss: 0.8275 - accuracy: 0.7515 - val_loss: 0.3018 - val_accuracy: 0.9136\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 26s 28ms/step - loss: 0.3762 - accuracy: 0.8853 - val_loss: 0.2277 - val_accuracy: 0.9343\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 25s 27ms/step - loss: 0.3094 - accuracy: 0.9064 - val_loss: 0.1840 - val_accuracy: 0.9453\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 25s 27ms/step - loss: 0.2683 - accuracy: 0.9194 - val_loss: 0.1613 - val_accuracy: 0.9517\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 24s 26ms/step - loss: 0.2388 - accuracy: 0.9275 - val_loss: 0.1439 - val_accuracy: 0.9557\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 25s 26ms/step - loss: 0.2213 - accuracy: 0.9332 - val_loss: 0.1297 - val_accuracy: 0.9626\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 24s 26ms/step - loss: 0.2058 - accuracy: 0.9374 - val_loss: 0.1243 - val_accuracy: 0.9610\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 25s 26ms/step - loss: 0.1902 - accuracy: 0.9420 - val_loss: 0.1117 - val_accuracy: 0.9670\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 25s 26ms/step - loss: 0.1823 - accuracy: 0.9450 - val_loss: 0.1108 - val_accuracy: 0.9664\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 24s 26ms/step - loss: 0.1739 - accuracy: 0.9484 - val_loss: 0.1011 - val_accuracy: 0.9694\n"
     ]
    }
   ],
   "source": [
    "optimizers = ['Adadelta', 'Adagrad', 'Adam', 'RMSprop', 'SGD']\n",
    "\n",
    "for i in optimizers:\n",
    "    model = build_model(i)\n",
    "    hist=model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23b0f97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
